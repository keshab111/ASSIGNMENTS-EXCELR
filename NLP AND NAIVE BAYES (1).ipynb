{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09089cd4-8182-4df9-a8d6-d091c0277e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Data       Labels\n",
      "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
      "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
      "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism\n",
      "Data      0\n",
      "Labels    0\n",
      "dtype: int64\n",
      "                                                     Data       Labels\n",
      "count                                                2000         2000\n",
      "unique                                               2000           20\n",
      "top     Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "freq                                                    1          100\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Data    2000 non-null   object\n",
      " 1   Labels  2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'blogs.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Summary statistics\n",
    "print(data.describe())\n",
    "\n",
    "# Data information\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b85485-24b2-45d5-ba5a-d6247c0825f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\MY\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Data       Labels\n",
      "0  path cantaloupesrvcscmuedumagnesiumclubcccmued...  alt.atheism\n",
      "1  newsgroups altatheism path cantaloupesrvcscmue...  alt.atheism\n",
      "2  path cantaloupesrvcscmuedudasnewsharvardedunoc...  alt.atheism\n",
      "3  path cantaloupesrvcscmuedumagnesiumclubcccmued...  alt.atheism\n",
      "4  xref cantaloupesrvcscmuedu altatheism talkreli...  alt.atheism\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the preprocessing function to the 'Data' column\n",
    "data['Data'] = data['Data'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1077db-e6b6-454b-abee-a1204cc9e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(data['Data']).toarray()\n",
    "y = data['Labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b7f7530-c4c7-476f-b9a2-96012a6a55aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Precision: 0.8466866785175607\n",
      "Recall: 0.84\n",
      "F1 Score: 0.8330936672448417\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.50      0.83      0.62        18\n",
      "           comp.graphics       0.75      0.83      0.79        18\n",
      " comp.os.ms-windows.misc       0.91      0.91      0.91        22\n",
      "comp.sys.ibm.pc.hardware       0.81      0.84      0.82        25\n",
      "   comp.sys.mac.hardware       0.86      0.90      0.88        21\n",
      "          comp.windows.x       0.95      0.84      0.89        25\n",
      "            misc.forsale       1.00      0.78      0.88        18\n",
      "               rec.autos       0.95      1.00      0.97        18\n",
      "         rec.motorcycles       0.94      0.94      0.94        16\n",
      "      rec.sport.baseball       0.80      0.89      0.84        18\n",
      "        rec.sport.hockey       0.88      1.00      0.94        15\n",
      "               sci.crypt       0.90      1.00      0.95        19\n",
      "         sci.electronics       0.67      0.75      0.71        16\n",
      "                 sci.med       0.88      0.88      0.88        17\n",
      "               sci.space       1.00      0.86      0.92        21\n",
      "  soc.religion.christian       0.92      0.96      0.94        23\n",
      "      talk.politics.guns       0.85      0.79      0.81        28\n",
      "   talk.politics.mideast       0.95      0.90      0.92        20\n",
      "      talk.politics.misc       0.76      0.89      0.82        18\n",
      "      talk.religion.misc       0.62      0.21      0.31        24\n",
      "\n",
      "                accuracy                           0.84       400\n",
      "               macro avg       0.85      0.85      0.84       400\n",
      "            weighted avg       0.85      0.84      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Implement the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e98bf99-e9c2-47bc-bab0-e4fe8d54da62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtextblob\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Function to get sentiment\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sentiment\u001b[39m(text):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to get sentiment\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 'positive'\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the sentiment function to the 'Data' column\n",
    "data['Sentiment'] = data['Data'].apply(get_sentiment)\n",
    "\n",
    "# Display the sentiment distribution\n",
    "print(data['Sentiment'].value_counts())\n",
    "\n",
    "# Examine the distribution of sentiments across different categories\n",
    "sentiment_distribution = pd.crosstab(data['Labels'], data['Sentiment'])\n",
    "print(sentiment_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24f82bef-90b9-400a-9245-06ebb79effae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Data       Labels\n",
      "0  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "1  Newsgroups: alt.atheism\\nPath: cantaloupe.srv....  alt.atheism\n",
      "2  Path: cantaloupe.srv.cs.cmu.edu!das-news.harva...  alt.atheism\n",
      "3  Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "4  Xref: cantaloupe.srv.cs.cmu.edu alt.atheism:53...  alt.atheism\n",
      "Data      0\n",
      "Labels    0\n",
      "dtype: int64\n",
      "                                                     Data       Labels\n",
      "count                                                2000         2000\n",
      "unique                                               2000           20\n",
      "top     Path: cantaloupe.srv.cs.cmu.edu!magnesium.club...  alt.atheism\n",
      "freq                                                    1          100\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Data    2000 non-null   object\n",
      " 1   Labels  2000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'blogs.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Check for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# Summary statistics\n",
    "print(data.describe())\n",
    "\n",
    "# Data information\n",
    "print(data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a59492cf-8b65-4f74-83d4-2bb8b88a77f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\MY\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Data       Labels\n",
      "0  path cantaloupesrvcscmuedumagnesiumclubcccmued...  alt.atheism\n",
      "1  newsgroups altatheism path cantaloupesrvcscmue...  alt.atheism\n",
      "2  path cantaloupesrvcscmuedudasnewsharvardedunoc...  alt.atheism\n",
      "3  path cantaloupesrvcscmuedumagnesiumclubcccmued...  alt.atheism\n",
      "4  xref cantaloupesrvcscmuedu altatheism talkreli...  alt.atheism\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Download NLTK stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    # Remove punctuation and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the preprocessing function to the 'Data' column\n",
    "data['Data'] = data['Data'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f8e0582-daa8-417e-a04c-b4e28cf639ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf_vectorizer.fit_transform(data['Data']).toarray()\n",
    "y = data['Labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99f457ff-c516-446a-bda6-a0a86b0e6747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Precision: 0.8466866785175607\n",
      "Recall: 0.84\n",
      "F1 Score: 0.8330936672448417\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.50      0.83      0.62        18\n",
      "           comp.graphics       0.75      0.83      0.79        18\n",
      " comp.os.ms-windows.misc       0.91      0.91      0.91        22\n",
      "comp.sys.ibm.pc.hardware       0.81      0.84      0.82        25\n",
      "   comp.sys.mac.hardware       0.86      0.90      0.88        21\n",
      "          comp.windows.x       0.95      0.84      0.89        25\n",
      "            misc.forsale       1.00      0.78      0.88        18\n",
      "               rec.autos       0.95      1.00      0.97        18\n",
      "         rec.motorcycles       0.94      0.94      0.94        16\n",
      "      rec.sport.baseball       0.80      0.89      0.84        18\n",
      "        rec.sport.hockey       0.88      1.00      0.94        15\n",
      "               sci.crypt       0.90      1.00      0.95        19\n",
      "         sci.electronics       0.67      0.75      0.71        16\n",
      "                 sci.med       0.88      0.88      0.88        17\n",
      "               sci.space       1.00      0.86      0.92        21\n",
      "  soc.religion.christian       0.92      0.96      0.94        23\n",
      "      talk.politics.guns       0.85      0.79      0.81        28\n",
      "   talk.politics.mideast       0.95      0.90      0.92        20\n",
      "      talk.politics.misc       0.76      0.89      0.82        18\n",
      "      talk.religion.misc       0.62      0.21      0.31        24\n",
      "\n",
      "                accuracy                           0.84       400\n",
      "               macro avg       0.85      0.85      0.84       400\n",
      "            weighted avg       0.85      0.84      0.83       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Implement the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a8248-9121-45e5-8b6e-27430f774c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to C:\\Users\\MY\n",
      "[nltk_data]     PC\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Download VADER lexicon\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize VADER sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get sentiment\n",
    "def get_sentiment(text):\n",
    "    score = sia.polarity_scores(text)['compound']\n",
    "    if score > 0:\n",
    "        return 'positive'\n",
    "    elif score < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply the sentiment function to the 'Data' column\n",
    "data['Sentiment'] = data['Data'].apply(get_sentiment)\n",
    "\n",
    "# Display the sentiment distribution\n",
    "print(data['Sentiment'].value_counts())\n",
    "\n",
    "# Examine the distribution of sentiments across different categories\n",
    "sentiment_distribution = pd.crosstab(data['Labels'], data['Sentiment'])\n",
    "print(sentiment_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9a899-4061-4b76-ac6b-6586811b501b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
